{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6390be79-e9cd-4c79-a0b1-105df2d0b4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| **Informa√ß√µes**    |            **Detalhes**         |\n",
    "|--------------------|---------------------------------|\n",
    "| Nome da Tabela     |          Silver_Pedidos         |\n",
    "| Data da Ingestao   |            31/03/2025           |\n",
    "| Ultima Atualiza√ßao |            30/07/2025           |\n",
    "| Origem             | bronze.pedidos/bronze.estabelecimentos   |\n",
    "| Respons√°vel        |           Lucas Sousa           |\n",
    "| Motivo             |   Cria√ß√£o de Camadas Silver     |\n",
    "| Observa√ß√µes        |               None              |\n",
    "\n",
    "## Hist√≥rico de Atualiza√ß√µes\n",
    " | Data | Desenvolvido por | Motivo |\n",
    " |:----:|--------------|--------|\n",
    " |27/05/2025 | Lucas Sousa  | Cria√ß√£o do notebook |\n",
    " |30/07/2025 | Lucas Sousa  | Otimiza√ß√µes no notebook |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1057f3eb-bbbf-49a9-9dd1-930042bdb5c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è [STATUS] Iniciando o pipeline Silver de pedidos.\nüü° [INFO] Verificando e criando o banco de dados 'silver' se necess√°rio.\nüü¢ [INFO] Leitura e enriquecimento de dados conclu√≠dos.\nüü¢ [INFO] Colunas de auditoria adicionadas.\nüü° [INFO] Tabela Delta j√° existe. Realizando opera√ß√£o MERGE para carga incremental.\nüü¢ [INFO] MERGE INTO conclu√≠do com sucesso.\nüü¢ [INFO] Garantindo o registro da tabela no metastore.\nüü¢ [INFO] Tabela registrada/sincronizada com sucesso.\nüü¢ [INFO] Iniciando tarefas de governan√ßa e otimiza√ß√£o.\nüìä [INFO] Aplicando coment√°rios na tabela 'silver.pedidos' e suas colunas...\nüü¢ [INFO] Coment√°rios aplicados com sucesso para 'silver.pedidos'.\nüöÄ [STATUS] Pipeline Silver conclu√≠do com sucesso! Tabela otimizada e documentada.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# #############################################################################\n",
    "# üì¶ Pipeline Silver - Transforma√ß√£o e Enriquecimento de Pedidos\n",
    "# Autor: Lucas Sousa, especialista em Engenharia de Dados\n",
    "# #############################################################################\n",
    "# üéØ Objetivo do C√≥digo:\n",
    "# Este script tem a miss√£o de atuar como o principal orquestrador do pipeline\n",
    "# da camada Silver. Ele executa as seguintes tarefas:\n",
    "# 1. L√™ os dados brutos de 'pedidos' e 'estabelecimentos' da camada Bronze.\n",
    "# 2. Aplica transforma√ß√µes de limpeza, tipagem correta e deduplica√ß√£o.\n",
    "# 3. Enriquecimento: Une os dados de pedidos com as informa√ß√µes dos estabelecimentos.\n",
    "# 4. Persist√™ncia: Grava o resultado na camada Silver usando Delta Lake,\n",
    "#    garantindo idempot√™ncia (evita duplicatas na re-execu√ß√£o) e evolu√ß√£o de schema.\n",
    "# 5. Governan√ßa: Registra a tabela no metastore do Spark com documenta√ß√£o (coment√°rios).\n",
    "# 6. Otimiza√ß√£o: Compacta e indexa a tabela Delta para acelerar consultas futuras.\n",
    "#\n",
    "# Demonstra dom√≠nio t√©cnico em:\n",
    "# - Modelagem de dados (Bronze -> Silver).\n",
    "# - Uso de SQL e DataFrames para transforma√ß√µes.\n",
    "# - Gerenciamento de tabela Delta Lake (MERGE, OPTIMIZE, VACUUM).\n",
    "# - Tratamento de erros e l√≥gica robusta de escrita (cria√ß√£o vs. atualiza√ß√£o).\n",
    "# - Boas pr√°ticas de governan√ßa (metadados e coment√°rios).\n",
    "# - Automa√ß√£o de pipelines de dados.\n",
    "# #############################################################################\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# üß© M√≥dulo 1: Importa√ß√µes Essenciais\n",
    "# -----------------------------------------------------------------------------\n",
    "# Importa fun√ß√µes do Spark SQL para manipula√ß√£o de colunas e express√µes.\n",
    "from pyspark.sql.functions import current_date, current_timestamp, expr \n",
    "# Importa a classe principal para interagir com tabelas Delta.\n",
    "from delta.tables import DeltaTable\n",
    "# Importa m√≥dulo para tratamento de exce√ß√µes espec√≠ficas do Spark.\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "# Importa m√≥dulo para interagir com o sistema de arquivos do Databricks (DBFS).\n",
    "import os \n",
    "import sys # M√≥dulo para escrever logs de erro no stderr.\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ‚öôÔ∏è M√≥dulo 2: Defini√ß√µes de Par√¢metros e Metadados\n",
    "# -----------------------------------------------------------------------------\n",
    "# Define o nome do banco de dados (schema) para a camada Silver.\n",
    "database = \"silver\"\n",
    "# Define o nome da tabela de destino.\n",
    "tabela = \"pedidos\"\n",
    "# Constr√≥i o nome completo da tabela para uso em comandos SQL.\n",
    "tabela_completa = f\"{database}.{tabela}\"\n",
    "# Define o caminho f√≠sico (localiza√ß√£o) da tabela Delta no DBFS.\n",
    "silver_path = \"dbfs:/FileStore/Ampev/silver/tables/pedidos\"\n",
    "\n",
    "# Coment√°rios de documenta√ß√£o para a tabela e suas colunas (governan√ßa de dados).\n",
    "# Essa documenta√ß√£o √© crucial para que os usu√°rios finais (analistas, cientistas de dados)\n",
    "# entendam a origem, o prop√≥sito e a estrutura dos dados.\n",
    "comentario_tabela = \"Esta tabela cont√©m pedidos enriquecidos com dados de estabelecimentos para an√°lise corporativa, pronta para consumo em relat√≥rios e dashboards.\"\n",
    "comentarios_colunas = {\n",
    "    'id_pedido': 'Identificador √∫nico do pedido, agora com tipagem INT.',\n",
    "    'id_estabelecimento': 'C√≥digo do estabelecimento associado ao pedido. Mantido como STRING para compatibilidade com a origem e evitar erros de CAST.',\n",
    "    'produto': 'Nome do produto vendido no pedido.',\n",
    "    'quantidade': 'Quantidade de itens vendidos, tipado como INT.',\n",
    "    'preco': 'Pre√ßo unit√°rio do produto, tipado como DECIMAL para precis√£o financeira.',\n",
    "    'nome_estabelecimento': 'Nome comercial do estabelecimento, obtido atrav√©s do JOIN com a tabela de estabelecimentos.',\n",
    "    'email': 'Email de contato do estabelecimento, para comunica√ß√£o e valida√ß√£o.',\n",
    "    'telefone': 'Telefone principal do estabelecimento.',\n",
    "    'data_pedido': 'Data da realiza√ß√£o do pedido, tipado como DATE.',\n",
    "    'data_carga': 'Data da carga t√©cnica para a camada Silver, usada para particionamento e auditoria.',\n",
    "    'data_hora_carga': 'Timestamp da carga exato (UTC-3) para granularidade de auditoria.'\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# üõ†Ô∏è M√≥dulo 3: Fun√ß√µes Auxiliares de Governan√ßa\n",
    "# -----------------------------------------------------------------------------\n",
    "def adiciona_comentarios_tabela(full_table_name: str, table_comment: str, column_comments: dict):\n",
    "    \"\"\"\n",
    "    Aplica coment√°rios descritivos a uma tabela e suas colunas no metastore do Spark.\n",
    "\n",
    "    Args:\n",
    "        full_table_name (str): Nome completo da tabela (ex: \"silver.pedidos\").\n",
    "        table_comment (str): Coment√°rio para a tabela.\n",
    "        column_comments (dict): Dicion√°rio com nomes das colunas e seus coment√°rios.\n",
    "    \"\"\"\n",
    "    print(f\"üìä [INFO] Aplicando coment√°rios na tabela '{full_table_name}' e suas colunas...\")\n",
    "    try:\n",
    "        # Tenta aplicar o coment√°rio na tabela.\n",
    "        spark.sql(f\"COMMENT ON TABLE {full_table_name} IS '{table_comment}'\")\n",
    "        # Itera sobre o dicion√°rio de coment√°rios e aplica cada um nas colunas.\n",
    "        for col_name, col_comment in column_comments.items():\n",
    "            spark.sql(f\"ALTER TABLE {full_table_name} CHANGE COLUMN {col_name} COMMENT '{col_comment}'\")\n",
    "        print(f\"üü¢ [INFO] Coment√°rios aplicados com sucesso para '{full_table_name}'.\")\n",
    "    except AnalysisException as e:\n",
    "        # Captura erros de cat√°logo e trata de forma n√£o fatal, pois o pipeline j√° salvou os dados.\n",
    "        print(f\"‚ö†Ô∏è [AVISO] Falha ao aplicar coment√°rios. Tabela '{full_table_name}' pode n√£o estar registrada no metastore. Erro: {e}\", file=sys.stderr)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è [AVISO] Ocorreu um erro inesperado ao aplicar coment√°rios. Erro: {e}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# üöÄ M√≥dulo 4: L√≥gica Principal de Transforma√ß√£o e Escrita\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    print(\"‚ñ∂Ô∏è [STATUS] Iniciando o pipeline Silver de pedidos.\")\n",
    "\n",
    "    # 1. Passo Cr√≠tico de Governan√ßa: Garante que o banco de dados 'silver' exista.\n",
    "    # Esta √© uma pr√°tica robusta que evita o erro `TABLE_OR_VIEW_NOT_FOUND`\n",
    "    # caso o schema n√£o tenha sido criado manualmente ou por um job anterior.\n",
    "    print(f\"üü° [INFO] Verificando e criando o banco de dados '{database}' se necess√°rio.\")\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {database}\")\n",
    "\n",
    "    # 2. Leitura e Enriquecimento:\n",
    "    # A query utiliza Common Table Expressions (CTEs) para melhorar a legibilidade e organizar\n",
    "    # o pipeline de transforma√ß√µes, seguindo uma pr√°tica de especialista.\n",
    "    # O JOIN Left √© usado para garantir que todos os pedidos da Bronze sejam mantidos,\n",
    "    # mesmo que n√£o haja um estabelecimento correspondente (o que resultaria em nulos).\n",
    "    df_pedidos_silver = spark.sql(f\"\"\"\n",
    "        WITH pedidos_limpos AS (\n",
    "            SELECT\n",
    "                CAST(PedidoID AS INT) AS id_pedido,\n",
    "                CAST(EstabelecimentoID AS STRING) AS id_estabelecimento,\n",
    "                Produto AS produto,\n",
    "                CAST(quantidade_vendida AS INT) AS quantidade,\n",
    "                CAST(Preco_Unitario AS DECIMAL(20,2)) AS preco,\n",
    "                CAST(data_venda AS DATE) AS data_pedido\n",
    "            FROM bronze.pedidos\n",
    "            WHERE PedidoID IS NOT NULL\n",
    "        ),\n",
    "        estabelecimentos_limpos AS (\n",
    "            SELECT\n",
    "                EstabelecimentoID AS id_estabelecimento,\n",
    "                Local AS nome_estabelecimento,\n",
    "                Email AS email,\n",
    "                Telefone AS telefone\n",
    "            FROM bronze.estabelecimentos\n",
    "        )\n",
    "        SELECT\n",
    "            ped.id_pedido,\n",
    "            ped.id_estabelecimento,\n",
    "            ped.produto,\n",
    "            ped.quantidade,\n",
    "            ped.preco,\n",
    "            est.nome_estabelecimento,\n",
    "            est.email,\n",
    "            est.telefone,\n",
    "            ped.data_pedido\n",
    "        FROM pedidos_limpos ped\n",
    "        LEFT JOIN estabelecimentos_limpos est\n",
    "        ON ped.id_estabelecimento = est.id_estabelecimento\n",
    "    \"\"\")\n",
    "    print(\"üü¢ [INFO] Leitura e enriquecimento de dados conclu√≠dos.\")\n",
    "    \n",
    "    # 3. Adi√ß√£o de Colunas T√©cnicas de Auditoria:\n",
    "    # Adiciona colunas para rastrear a data e hora da carga, crucial para linhagem e auditoria.\n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\"data_carga\", current_date())\n",
    "    # O fuso hor√°rio √© ajustado para evitar inconsist√™ncias.\n",
    "    df_pedidos_silver = df_pedidos_silver.withColumn(\"data_hora_carga\", expr(\"current_timestamp() - INTERVAL 3 HOURS\"))\n",
    "    print(\"üü¢ [INFO] Colunas de auditoria adicionadas.\")\n",
    "    \n",
    "    # 4. Verifica√ß√£o e Escrita da Tabela Delta:\n",
    "    # A l√≥gica foi aprimorada para garantir que, independentemente da carga,\n",
    "    # as opera√ß√µes de grava√ß√£o e registro no cat√°logo estejam sincronizadas.\n",
    "    \n",
    "    # Verifica se a tabela Delta j√° existe fisicamente no DBFS.\n",
    "    if DeltaTable.isDeltaTable(spark, silver_path):\n",
    "        # Se a tabela existe, usamos MERGE INTO para garantir UPSERT (atualiza√ß√£o ou inser√ß√£o).\n",
    "        # A carga incremental √© mais robusta com MERGE do que com APPEND + deduplica√ß√£o posterior.\n",
    "        print(\"üü° [INFO] Tabela Delta j√° existe. Realizando opera√ß√£o MERGE para carga incremental.\")\n",
    "        delta_table = DeltaTable.forPath(spark, silver_path)\n",
    "        \n",
    "        # A l√≥gica MERGE √© a forma mais robusta e eficiente de lidar com cargas incrementais\n",
    "        # e deduplica√ß√£o sem ter que reprocessar toda a tabela.\n",
    "        delta_table.alias(\"tgt\") \\\n",
    "            .merge(\n",
    "                df_pedidos_silver.alias(\"src\"),\n",
    "                \"tgt.id_pedido = src.id_pedido\" # Condi√ß√£o de jun√ß√£o para a MERGE.\n",
    "            ) \\\n",
    "            .whenMatchedUpdateAll() \\\n",
    "            .whenNotMatchedInsertAll() \\\n",
    "            .execute()\n",
    "        \n",
    "        print(\"üü¢ [INFO] MERGE INTO conclu√≠do com sucesso.\")\n",
    "        \n",
    "    else:\n",
    "        # Se a tabela n√£o existe, fazemos a primeira carga.\n",
    "        print(\"üü° [INFO] Tabela Delta n√£o existe. Realizando a primeira carga e cria√ß√£o da tabela.\")\n",
    "        (\n",
    "            df_pedidos_silver.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\") # 'overwrite' na primeira carga para garantir um estado limpo.\n",
    "            .option(\"mergeSchema\", \"true\") # Permite a evolu√ß√£o de schema j√° na primeira carga.\n",
    "            .partitionBy(\"data_carga\") # Particionamento para otimizar leituras.\n",
    "            .save(silver_path)\n",
    "        )\n",
    "        print(\"üü¢ [INFO] Dados salvos e tabela Delta criada no DBFS.\")\n",
    "\n",
    "    # 5. Governan√ßa e Otimiza√ß√£o:\n",
    "    # Esta √© a principal altera√ß√£o para corrigir o erro. A cria√ß√£o da tabela no cat√°logo\n",
    "    # agora √© chamada em ambos os cen√°rios (primeira carga ou carga incremental), garantindo que\n",
    "    # o metadado no cat√°logo do Spark esteja sempre sincronizado com o caminho f√≠sico do Delta.\n",
    "    # Isso resolve o erro `TABLE_OR_VIEW_NOT_FOUND` se a tabela existir fisicamente, mas n√£o\n",
    "    # logicamente no metastore.\n",
    "    print(\"üü¢ [INFO] Garantindo o registro da tabela no metastore.\")\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {tabela_completa}\n",
    "        USING DELTA\n",
    "        LOCATION '{silver_path}'\n",
    "    \"\"\")\n",
    "    print(\"üü¢ [INFO] Tabela registrada/sincronizada com sucesso.\")\n",
    "    \n",
    "    print(\"üü¢ [INFO] Iniciando tarefas de governan√ßa e otimiza√ß√£o.\")\n",
    "    adiciona_comentarios_tabela(tabela_completa, comentario_tabela, comentarios_colunas)\n",
    "    \n",
    "    # Otimiza√ß√£o com Z-Ordering √© uma t√©cnica avan√ßada que co-localiza dados relacionados\n",
    "    # em arquivos no DBFS, acelerando consultas que filtram por essas colunas.\n",
    "    # O 'id_pedido' √© uma √≥tima escolha para Z-Ordering.\n",
    "    spark.sql(f\"OPTIMIZE {tabela_completa} ZORDER BY (id_pedido)\")\n",
    "    \n",
    "    # VACUUM remove arquivos de dados que n√£o s√£o mais referenciados pela tabela Delta,\n",
    "    # limpando o hist√≥rico e liberando espa√ßo em disco. O RETENTION garante a seguran√ßa.\n",
    "    spark.sql(f\"VACUUM {tabela_completa} RETAIN 168 HOURS\") # 168 horas = 7 dias.\n",
    "    \n",
    "    print(\"üöÄ [STATUS] Pipeline Silver conclu√≠do com sucesso! Tabela otimizada e documentada.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # O bloco 'except' captura qualquer erro grave e exibe uma mensagem clara.\n",
    "    print(f\"‚ùå [ERRO CR√çTICO] O pipeline Silver falhou. Erro: {str(e)}\", file=sys.stderr)\n",
    "    raise e # Re-lan√ßa o erro para que a orquestra√ß√£o externa (como um job) possa captur√°-lo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc4df901-db3b-4528-8806-f6049e4c4e51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id_pedido</th><th>id_estabelecimento</th><th>produto</th><th>quantidade</th><th>preco</th><th>nome_estabelecimento</th><th>email</th><th>telefone</th><th>data_pedido</th><th>data_carga</th><th>data_hora_carga</th></tr></thead><tbody><tr><td>17</td><td>7</td><td>Refrigerante 123</td><td>393</td><td>10.29</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2023-12-23</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>19</td><td>7</td><td>Refrigerante 123</td><td>314</td><td>19.87</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2024-02-18</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>95</td><td>7</td><td>Vinho ABC</td><td>205</td><td>11.64</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2023-08-27</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>185</td><td>7</td><td>√Ågua Mineral</td><td>190</td><td>7.10</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2024-04-10</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>203</td><td>7</td><td>Cerveja XYZ</td><td>173</td><td>14.00</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2023-09-12</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>104</td><td>7</td><td>Suco Natural</td><td>107</td><td>1.72</td><td>Pizzaria Bella</td><td>contato@pizzariabella.com</td><td>(91) 96418-7540</td><td>2023-12-11</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>39</td><td>15</td><td>Cerveja XYZ</td><td>315</td><td>16.31</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-01-14</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>227</td><td>15</td><td>Vinho ABC</td><td>194</td><td>14.54</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-05-12</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>9</td><td>15</td><td>Suco Natural</td><td>62</td><td>6.25</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-01-20</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>215</td><td>15</td><td>√Ågua Mineral</td><td>92</td><td>2.23</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2023-09-10</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>44</td><td>15</td><td>Refrigerante 123</td><td>390</td><td>18.11</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-01-29</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>86</td><td>15</td><td>Vinho ABC</td><td>157</td><td>4.05</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-04-24</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>180</td><td>15</td><td>Vinho ABC</td><td>200</td><td>17.31</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2023-08-02</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>152</td><td>15</td><td>Vinho ABC</td><td>329</td><td>3.27</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2024-02-24</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>199</td><td>15</td><td>Refrigerante 123</td><td>440</td><td>6.88</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2023-09-05</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>80</td><td>15</td><td>√Ågua Mineral</td><td>494</td><td>18.05</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2023-11-11</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>125</td><td>15</td><td>√Ågua Mineral</td><td>404</td><td>18.28</td><td>Padoca do Z√©</td><td>contato@padocadodze.com</td><td>(61) 94617-3404</td><td>2023-11-22</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>168</td><td>11</td><td>√Ågua Mineral</td><td>199</td><td>16.53</td><td>Doceria Del√≠cia</td><td>contato@doceriadelicia.com</td><td>(61) 95626-8430</td><td>2023-12-19</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>211</td><td>11</td><td>Cerveja XYZ</td><td>270</td><td>12.22</td><td>Doceria Del√≠cia</td><td>contato@doceriadelicia.com</td><td>(61) 95626-8430</td><td>2024-03-12</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr><tr><td>119</td><td>11</td><td>√Ågua Mineral</td><td>337</td><td>12.01</td><td>Doceria Del√≠cia</td><td>contato@doceriadelicia.com</td><td>(61) 95626-8430</td><td>2023-10-15</td><td>2025-08-03</td><td>2025-08-03T19:20:13.487Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         17,
         7,
         "Refrigerante 123",
         393,
         "10.29",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2023-12-23",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         19,
         7,
         "Refrigerante 123",
         314,
         "19.87",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2024-02-18",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         95,
         7,
         "Vinho ABC",
         205,
         "11.64",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2023-08-27",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         185,
         7,
         "√Ågua Mineral",
         190,
         "7.10",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2024-04-10",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         203,
         7,
         "Cerveja XYZ",
         173,
         "14.00",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2023-09-12",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         104,
         7,
         "Suco Natural",
         107,
         "1.72",
         "Pizzaria Bella",
         "contato@pizzariabella.com",
         "(91) 96418-7540",
         "2023-12-11",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         39,
         15,
         "Cerveja XYZ",
         315,
         "16.31",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-01-14",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         227,
         15,
         "Vinho ABC",
         194,
         "14.54",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-05-12",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         9,
         15,
         "Suco Natural",
         62,
         "6.25",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-01-20",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         215,
         15,
         "√Ågua Mineral",
         92,
         "2.23",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2023-09-10",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         44,
         15,
         "Refrigerante 123",
         390,
         "18.11",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-01-29",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         86,
         15,
         "Vinho ABC",
         157,
         "4.05",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-04-24",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         180,
         15,
         "Vinho ABC",
         200,
         "17.31",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2023-08-02",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         152,
         15,
         "Vinho ABC",
         329,
         "3.27",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2024-02-24",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         199,
         15,
         "Refrigerante 123",
         440,
         "6.88",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2023-09-05",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         80,
         15,
         "√Ågua Mineral",
         494,
         "18.05",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2023-11-11",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         125,
         15,
         "√Ågua Mineral",
         404,
         "18.28",
         "Padoca do Z√©",
         "contato@padocadodze.com",
         "(61) 94617-3404",
         "2023-11-22",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         168,
         11,
         "√Ågua Mineral",
         199,
         "16.53",
         "Doceria Del√≠cia",
         "contato@doceriadelicia.com",
         "(61) 95626-8430",
         "2023-12-19",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         211,
         11,
         "Cerveja XYZ",
         270,
         "12.22",
         "Doceria Del√≠cia",
         "contato@doceriadelicia.com",
         "(61) 95626-8430",
         "2024-03-12",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ],
        [
         119,
         11,
         "√Ågua Mineral",
         337,
         "12.01",
         "Doceria Del√≠cia",
         "contato@doceriadelicia.com",
         "(61) 95626-8430",
         "2023-10-15",
         "2025-08-03",
         "2025-08-03T19:20:13.487Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"Identificador √∫nico do pedido, agora com tipagem INT.\"}",
         "name": "id_pedido",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"comment\":\"C√≥digo do estabelecimento associado ao pedido. Mantido como STRING para compatibilidade com a origem e evitar erros de CAST.\"}",
         "name": "id_estabelecimento",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"comment\":\"Nome do produto vendido no pedido.\"}",
         "name": "produto",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"Quantidade de itens vendidos, tipado como INT.\"}",
         "name": "quantidade",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"comment\":\"Pre√ßo unit√°rio do produto, tipado como DECIMAL para precis√£o financeira.\"}",
         "name": "preco",
         "type": "\"decimal(20,2)\""
        },
        {
         "metadata": "{\"comment\":\"Nome comercial do estabelecimento, obtido atrav√©s do JOIN com a tabela de estabelecimentos.\"}",
         "name": "nome_estabelecimento",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"Email de contato do estabelecimento, para comunica√ß√£o e valida√ß√£o.\"}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"Telefone principal do estabelecimento.\"}",
         "name": "telefone",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"Data da realiza√ß√£o do pedido, tipado como DATE.\"}",
         "name": "data_pedido",
         "type": "\"date\""
        },
        {
         "metadata": "{\"comment\":\"Data da carga t√©cnica para a camada Silver, usada para particionamento e auditoria.\"}",
         "name": "data_carga",
         "type": "\"date\""
        },
        {
         "metadata": "{\"comment\":\"Timestamp da carga exato (UTC-3) para granularidade de auditoria.\"}",
         "name": "data_hora_carga",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM silver.pedidos LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2d042f-1530-4a60-8145-4335d93dbd51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Log de execu√ß√£o da camada Silver registrado com sucesso!\nüìå Job: silver_pedidos\nüì¶ Status: SUCESSO | Registros processados: 250 | Dura√ß√£o: 2.38 segundos\n"
     ]
    }
   ],
   "source": [
    "# üìã Registro de Log de Execu√ß√£o Delta ‚Äì Camada Silver\n",
    "# üéØ Objetivo: rastrear a execu√ß√£o da camada Silver de forma audit√°vel e resiliente\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DoubleType\n",
    "import time\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 1. In√≠cio da medi√ß√£o de tempo da execu√ß√£o\n",
    "# ------------------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 2. Identifica√ß√£o l√≥gica do job atual\n",
    "# ------------------------------------------\n",
    "job_name = \"silver_pedidos\"  # üîÅ Altere conforme o pipeline\n",
    "\n",
    "try:\n",
    "    # ----------------------------------------------------\n",
    "    # ‚úÖ 3. Simula√ß√£o de processamento da camada Silver\n",
    "    #    Substitua este trecho pelo seu pipeline real\n",
    "    # ----------------------------------------------------\n",
    "    df = spark.table(\"silver.pedidos\")  # Exemplo: leitura da tabela j√° processada\n",
    "    qtd_linhas = df.count()  # Contagem ap√≥s transforma√ß√£o\n",
    "\n",
    "    status = \"SUCESSO\"\n",
    "    erro = None\n",
    "\n",
    "except Exception as e:\n",
    "    # üß® Captura qualquer erro ocorrido durante o pipeline\n",
    "    qtd_linhas = 0\n",
    "    status = \"ERRO\"\n",
    "    erro = str(e)\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 4. Medi√ß√£o do tempo total de execu√ß√£o\n",
    "# ------------------------------------------\n",
    "tempo_total = round(time.time() - start_time, 2)\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 5. Defini√ß√£o do schema expl√≠cito para o log Delta\n",
    "# ------------------------------------------\n",
    "log_schema = StructType([\n",
    "    StructField(\"job_name\", StringType(), True),\n",
    "    StructField(\"data_execucao\", TimestampType(), True),\n",
    "    StructField(\"qtd_linhas\", IntegerType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"erro\", StringType(), True),\n",
    "    StructField(\"tempo_total_segundos\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 6. Cria√ß√£o do DataFrame de log com metadados t√©cnicos\n",
    "# ------------------------------------------\n",
    "log_df = spark.createDataFrame([(\n",
    "    job_name,\n",
    "    None,  # Timestamp preenchido com a fun√ß√£o atualizada abaixo\n",
    "    qtd_linhas,\n",
    "    status,\n",
    "    erro,\n",
    "    tempo_total\n",
    ")], schema=log_schema).withColumn(\"data_execucao\", current_timestamp())\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 7. Caminhos de armazenamento do log na camada Silver\n",
    "# ------------------------------------------\n",
    "LOG_PATH = \"dbfs:/FileStore/Ampev/logs/silver_pedidos\"  # Delta Storage\n",
    "LOG_TABLE = \"silver.logs_pedidos\"  # Cat√°logo Delta\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 8. Escrita segura e resiliente no Delta Lake\n",
    "# - Garante que o log seja incremental e tolerante a mudan√ßas de schema\n",
    "# ------------------------------------------\n",
    "log_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(LOG_PATH)\n",
    "\n",
    "# Cria a tabela Delta no cat√°logo se n√£o existir\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {LOG_TABLE}\n",
    "    USING DELTA\n",
    "    LOCATION '{LOG_PATH}'\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# ‚úÖ 9. Feedback visual para o engenheiro\n",
    "# ------------------------------------------\n",
    "print(\"‚úÖ Log de execu√ß√£o da camada Silver registrado com sucesso!\")\n",
    "print(f\"üìå Job: {job_name}\")\n",
    "print(f\"üì¶ Status: {status} | Registros processados: {qtd_linhas} | Dura√ß√£o: {tempo_total} segundos\")\n",
    "if erro:\n",
    "    print(f\"‚ö†Ô∏è Detalhes do erro registrado no log: {erro}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b131930-72b9-4f01-908f-6dc1434aa403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job_name</th><th>data_execucao</th><th>qtd_linhas</th><th>status</th><th>erro</th><th>tempo_total_segundos</th></tr></thead><tbody><tr><td>silver_pedidos</td><td>2025-07-31T00:13:45.969Z</td><td>750</td><td>SUCESSO</td><td>null</td><td>1.57</td></tr><tr><td>silver_pedidos</td><td>2025-08-01T01:24:56.792Z</td><td>250</td><td>SUCESSO</td><td>null</td><td>2.67</td></tr><tr><td>silver_pedidos</td><td>2025-08-03T22:21:42.659Z</td><td>250</td><td>SUCESSO</td><td>null</td><td>2.38</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "silver_pedidos",
         "2025-07-31T00:13:45.969Z",
         750,
         "SUCESSO",
         null,
         1.57
        ],
        [
         "silver_pedidos",
         "2025-08-01T01:24:56.792Z",
         250,
         "SUCESSO",
         null,
         2.67
        ],
        [
         "silver_pedidos",
         "2025-08-03T22:21:42.659Z",
         250,
         "SUCESSO",
         null,
         2.38
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 4
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "job_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_execucao",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "qtd_linhas",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "status",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "erro",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tempo_total_segundos",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM silver.logs_pedidos"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2180081326335882,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Pedidos",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}