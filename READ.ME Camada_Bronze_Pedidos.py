# Databricks notebook source
# MAGIC %md
# MAGIC # üì¶ Pipeline Bronze - Ingest√£o e Governan√ßa de Dados de Pedidos (CSV ‚ûù Delta Lake)
# MAGIC
# MAGIC üë®‚Äçüíª **Autor:** Lucas Sousa Santos Oliveira  
# MAGIC üéØ **Especialista em Finan√ßas em transi√ß√£o para Engenharia de Dados** | P√≥s-gradua√ß√£o em Big Data e Cloud Computing
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## üéØ Objetivo do Projeto
# MAGIC
# MAGIC Este notebook implementa um **pipeline de ingest√£o robusto e escal√°vel** para carregar dados brutos de **pedidos** (CSV) na **Camada Bronze** de um Data Lakehouse utilizando **Delta Lake** no Databricks.
# MAGIC
# MAGIC O pipeline garante:
# MAGIC
# MAGIC - ‚úÖ **Qualidade na origem** com schema enforcement
# MAGIC - üîÅ **Upsert incremental** usando `MERGE INTO`
# MAGIC - üß† **Rastreabilidade completa** com metadados t√©cnicos
# MAGIC - ‚öôÔ∏è **Otimiza√ß√£o de performance** com particionamento, `OPTIMIZE ZORDER` e `VACUUM`
# MAGIC - üõ° **Governan√ßa e confiabilidade** com registro no metastore
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## üß± Arquitetura do Pipeline
# MAGIC
# MAGIC ```mermaid
# MAGIC flowchart TD
# MAGIC     A[üìÑ CSV - Pedidos] --> B[üì• Leitura com Schema Enforcement]
# MAGIC     B --> C[üßπ Limpeza e Valida√ß√£o Inicial]
# MAGIC     C --> D[üß† Enriquecimento com data_ingestao]
# MAGIC     D --> E[üß≠ Reparticionamento Estrat√©gico]
# MAGIC     E --> F{Tabela Delta existe?}
# MAGIC     F -- Sim --> G[üîÅ MERGE INTO para UPSERT]
# MAGIC     F -- N√£o --> H[üÜï Cria√ß√£o Inicial da Tabela Delta]
# MAGIC     G & H --> I[üõ° Registro no Metastore]
# MAGIC     I --> J[‚öôÔ∏è OPTIMIZE ZORDER BY (PedidoID)]
# MAGIC     J --> K[üßº VACUUM 168 HOURS]
# MAGIC ```
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## üìä T√©cnicas e Boas Pr√°ticas Aplicadas
# MAGIC
# MAGIC | T√©cnica / Pr√°tica                       | Objetivo / Benef√≠cio |
# MAGIC |-----------------------------------------|----------------------|
# MAGIC | **Schema Enforcement (StructType)**    | Garante tipagem correta e evita infer√™ncia inconsistente |
# MAGIC | **Tratamento de registros inv√°lidos**   | Remove dados malformados prevenindo falhas no MERGE |
# MAGIC | **Deduplica√ß√£o e filtro de nulos**      | Assegura integridade da chave prim√°ria |
# MAGIC | **Coluna `data_ingestao`**              | Rastreabilidade e suporte a Time Travel |
# MAGIC | **Reparticionamento por chave**         | Melhora performance em escrita e consultas futuras |
# MAGIC | **`CREATE TABLE IF NOT EXISTS`**        | Garante visibilidade no cat√°logo e previne erros |
# MAGIC | **`MERGE INTO` (Upsert)**               | Atualiza e insere registros de forma incremental e ACID |
# MAGIC | **`OPTIMIZE ZORDER`**                   | Melhora filtragem e leitura |
# MAGIC | **`VACUUM`**                            | Reduz custo de armazenamento removendo arquivos obsoletos |
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## üõ† Fluxo Detalhado
# MAGIC
# MAGIC ### 1Ô∏è‚É£ Leitura do CSV com Schema Enforcement
# MAGIC
# MAGIC ```python
# MAGIC from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType
# MAGIC
# MAGIC schema = StructType([
# MAGIC     StructField("PedidoID", StringType(), True),
# MAGIC     StructField("EstabelecimentoID", StringType(), True),
# MAGIC     StructField("Produto", StringType(), True),
# MAGIC     StructField("quantidade_vendida", IntegerType(), True),
# MAGIC     StructField("Preco_Unitario", DoubleType(), True),
# MAGIC     StructField("data_venda", DateType(), True)
# MAGIC ])
# MAGIC
# MAGIC df_raw = (
# MAGIC     spark.read.format("csv")
# MAGIC     .option("header", "true")
# MAGIC     .option("mode", "DROPMALFORMED")
# MAGIC     .schema(schema)
# MAGIC     .load("dbfs:/FileStore/Ampev/pedidos.csv")
# MAGIC )
# MAGIC ```
# MAGIC
# MAGIC üìå *Por que?* ‚Äî Evita infer√™ncia autom√°tica e garante consist√™ncia entre execu√ß√µes.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 2Ô∏è‚É£ Limpeza e Valida√ß√£o
# MAGIC
# MAGIC ```python
# MAGIC df_clean = (
# MAGIC     df_raw.dropDuplicates()
# MAGIC           .na.drop()
# MAGIC           .filter("PedidoID IS NOT NULL AND TRIM(PedidoID) != ''")
# MAGIC )
# MAGIC ```
# MAGIC
# MAGIC üìå *Por que?* ‚Äî Remove duplicatas, nulos e registros sem chave para evitar falhas no upsert.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 3Ô∏è‚É£ Enriquecimento e Reparticionamento
# MAGIC
# MAGIC ```python
# MAGIC from pyspark.sql.functions import current_timestamp
# MAGIC
# MAGIC df_partitioned = (
# MAGIC     df_clean.withColumn("data_ingestao", current_timestamp())
# MAGIC             .repartition("PedidoID")
# MAGIC )
# MAGIC ```
# MAGIC
# MAGIC üìå *Por que?* ‚Äî Adiciona rastreabilidade e melhora performance de escrita.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 4Ô∏è‚É£ Escrita com MERGE INTO
# MAGIC
# MAGIC ```python
# MAGIC from delta.tables import DeltaTable
# MAGIC
# MAGIC if DeltaTable.isDeltaTable(spark, "dbfs:/FileStore/Ampev/tables/bronze/pedidos"):
# MAGIC     delta_table = DeltaTable.forPath(spark, "dbfs:/FileStore/Ampev/tables/bronze/pedidos")
# MAGIC     (
# MAGIC         delta_table.alias("tgt")
# MAGIC         .merge(df_partitioned.alias("src"), "tgt.PedidoID = src.PedidoID")
# MAGIC         .whenMatchedUpdateAll()
# MAGIC         .whenNotMatchedInsertAll()
# MAGIC         .execute()
# MAGIC     )
# MAGIC else:
# MAGIC     df_partitioned.write.format("delta")         .partitionBy("data_ingestao")         .option("mergeSchema", "true")         .mode("overwrite")         .save("dbfs:/FileStore/Ampev/tables/bronze/pedidos")
# MAGIC ```
# MAGIC
# MAGIC üìå *Por que?* ‚Äî Garante ingest√£o incremental sem sobrescrever dados √≠ntegros.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ### 5Ô∏è‚É£ Otimiza√ß√£o e Manuten√ß√£o
# MAGIC
# MAGIC ```sql
# MAGIC OPTIMIZE bronze.pedidos ZORDER BY (PedidoID);
# MAGIC VACUUM bronze.pedidos RETAIN 168 HOURS;
# MAGIC ```
# MAGIC
# MAGIC üìå *Por que?* ‚Äî Compacta arquivos, melhora filtragem e libera espa√ßo.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## ‚úÖ Resultado Esperado
# MAGIC
# MAGIC | M√©trica                     | Valor                          |
# MAGIC |-----------------------------|--------------------------------|
# MAGIC | üìå Tabela Delta Criada       | `bronze.pedidos`               |
# MAGIC | üîë Chave de Neg√≥cio         | `PedidoID`                     |
# MAGIC | üßæ Particionamento F√≠sico   | `data_ingestao`                 |
# MAGIC | ‚öôÔ∏è Otimiza√ß√µes Aplicadas     | `OPTIMIZE ZORDER + VACUUM`     |
# MAGIC | üîÅ Tipo de Ingest√£o         | `Batch` + `MERGE INTO`         |
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## üß† Conclus√£o
# MAGIC
# MAGIC Este pipeline √© **produ√ß√£o-ready** e incorpora princ√≠pios modernos de engenharia de dados:
# MAGIC
# MAGIC - üìä Qualidade desde a origem
# MAGIC - üîÅ Idempot√™ncia e resili√™ncia
# MAGIC - ‚ö° Performance otimizada para custo e velocidade
# MAGIC - üõ° Governan√ßa e rastreabilidade completas
# MAGIC - üöÄ Pronto para evolu√ß√£o futura com streaming, camada Silver e Gold